{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "similiar_image.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "w2com2Jq-WF3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tgtrICST-dU5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"ggplot\")\n",
        "%matplotlib inline\n",
        "\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from itertools import chain\n",
        "from skimage.io import imread, imshow, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import label\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
        "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
        "from keras.layers.merge import concatenate, add\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import h5py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M31UvS02-hB_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hdf5_path = '/content/drive/My Drive/similiarimagedataset_dreambot_weddingcard_300_new_classi_slider.hdf5'\n",
        "# hdf5_pathtest = '/content/drive/My Drive/similiarimagedataset_dreambot_test_500.hdf5'\n",
        "hdf5_file = h5py.File(hdf5_path, \"r\")\n",
        "# hdf5_filetest = h5py.File(hdf5_pathtest, \"r\")\n",
        "\n",
        "# reshape to be [samples][pixels][width][height]\n",
        "X_train = hdf5_file.get('train_img').value\n",
        "# Y_train = hdf5_file.get('train_labels').value\n",
        "# X_val  = hdf5_filetest.get('val_img').value\n",
        "# y_val  = hdf5_filetest.get('val_labels').value\n",
        "# X_test  = hdf5_filetest.get('test_img').value\n",
        "# y_test  = hdf5_filetest.get('test_labels').value\n",
        "# X_train = X_train.reshape(X_train.shape[2],X_train.shape[1],X_train.shape[0])\n",
        "# X_test = X_test.reshape(X_test.shape[2],X_test.shape[1],X_test.shape[0])\n",
        "hdf5_file.close()\n",
        "X_train = X_train.reshape(X_train.shape[0], 300, 300,3).astype('float32')\n",
        "# X_test = X_test.reshape(X_test.shape[0], 500, 500,3).astype('float32')\n",
        "# X_val  = X_val.reshape(X_val.shape[0], 299, 299,3).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fM6s7AF0-kSR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# X_train = X_train.astype('uint32')/255\n",
        "X_train_list = []\n",
        "X_train_resized = []\n",
        "for i in range(len(X_train)):\n",
        "  img = cv2.resize(X_train[i], (256, 256), interpolation=cv2.INTER_CUBIC)\n",
        "  X_train_resized.append(img)\n",
        "X_train_resized = np.array(X_train_resized)\n",
        "imagedatagen = ImageDataGenerator(samplewise_center=True,samplewise_std_normalization=True)\n",
        "# for i in range(len(X_train)):\n",
        "imagedatagen.fit(X_train_resized)\n",
        "batchgen = imagedatagen.flow(X_train_resized,batch_size=769,shuffle=False)\n",
        "X_train = batchgen.next()\n",
        "plt.imshow(X_train[0])\n",
        "\n",
        "\n",
        "\n",
        "# hdf5_path = '/content/drive/My Drive/similiarimagedataset_dreambot_weddingcard_256new2.hdf5'\n",
        "# train_addrs = X_train\n",
        "# # elif data_order == 'tf':\n",
        "# train_shape = (len(train_addrs), 256, 256,3)\n",
        "# #     val_shape = (len(val_addrs), 299, 299,3)\n",
        "# #     test_shape = (len(test_addrs), 299, 299,3)QA\n",
        "# # open a hdf5 file and create earrays\n",
        "# hdf5_file = h5py.File(hdf5_path, mode='w')\n",
        "# hdf5_file.create_dataset(\"train_img\", train_shape, np.int32)\n",
        "# hdf5_file.create_dataset(\"train_labels\", (len(train_addrs),12), np.int32)\n",
        "# hdf5_file[\"train_labels\"][...] = Y_train\n",
        "\n",
        "#         img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "# #   img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "#   hdf5_file[\"train_img\"][i, ...] = img[None]\n",
        "# # X_train = X_train.astype('float32')/255.0\n",
        "# # X_tests  = X_test.astype('float32')/255.0\n",
        "# # for i,j in X_train:\n",
        "# #     mean = np.mean(i, axis=(0, 1, 2))\n",
        "# # #   print(mean)\n",
        "# #     i -= mean\n",
        "# # for i in X_test:\n",
        "# #   mean = np.mean(i, axis=(0, 1, 2))\n",
        "# #   i -= mean\n",
        "# hdf5_file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KbRduGzN-mrQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(X_train[0].reshape(300,300,3).astype('int32'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M92mnMQF-r7Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):\n",
        "    # first layer\n",
        "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
        "               padding=\"same\")(input_tensor)\n",
        "    if batchnorm:\n",
        "        x = BatchNormalization()(x)\n",
        "    x = Activation(\"elu\")(x)\n",
        "    # second layer\n",
        "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
        "               padding=\"same\")(x)\n",
        "    if batchnorm:\n",
        "        x = BatchNormalization()(x)\n",
        "    x = Activation(\"elu\")(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gCtPttsw_JzC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_unet(input_img, n_filters=16, dropout=0.5, batchnorm=True):\n",
        "    # contracting path\n",
        "    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
        "    p1 = MaxPooling2D((2, 2)) (c1)\n",
        "    p1 = Dropout(dropout*0.5)(p1)\n",
        "\n",
        "    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
        "    p2 = MaxPooling2D((2, 2)) (c2)\n",
        "    p2 = Dropout(dropout)(p2)\n",
        "\n",
        "    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
        "    p3 = MaxPooling2D((2, 2)) (c3)\n",
        "    p3 = Dropout(dropout)(p3)\n",
        "\n",
        "    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
        "    p4 = Dropout(dropout)(p4)\n",
        "    \n",
        "    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)\n",
        "    \n",
        "    # expansive path\n",
        "    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)\n",
        "#     u6 = concatenate([u6, c4])\n",
        "    u6 = Dropout(dropout)(u6)\n",
        "    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
        "\n",
        "    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)\n",
        "#     u7 = concatenate([u7, c3])\n",
        "    u7 = Dropout(dropout)(u7)\n",
        "    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
        "\n",
        "    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)\n",
        "#     u8 = concatenate([u8, c2])\n",
        "    u8 = Dropout(dropout)(u8)\n",
        "    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
        "\n",
        "    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)\n",
        "#     u9 = concatenate([u9, c1], axis=3)\n",
        "    u9 = Dropout(dropout)(u9)\n",
        "    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
        "    \n",
        "    outputs = Conv2D(3, (1, 1), activation='tanh') (c9)\n",
        "    \n",
        "    \n",
        "#     flatten = Flatten()(c5)\n",
        "#     x   = Dense(500, activation='relu')(flatten)\n",
        "#     x   = Dense(250, activation='relu')(x)\n",
        "#     x   = Dense(50, activation='relu')(x)\n",
        "#     dense_layer_output   = Dense(12, activation='hard_sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=[input_img], outputs=[outputs])#,dense_layer_output])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uRxpZMdI_MA7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_img = Input((256, 256, 3), name='img')\n",
        "model = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\n",
        "\n",
        "model.compile(optimizer=Adam(), loss=\"mean_squared_error\")#,\"mean_squared_error\"])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LBoofADg_Oue",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train,X_train,batch_size=30,epochs=200,shuffle='batch')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p1KqXEvf_SoZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "try:\n",
        "    model_json = model.to_json()\n",
        "    with open(\"/content/drive/My Drive/similiarautoencoder_final_256new_unet_onlyautoencoder_use_slider.json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "except:\n",
        "    pass\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"/content/drive/My Drive/similiarautoencoder_final_256new_unet_onlyautoencoder_use_slider.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WU7f5o7M_V8V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(model.predict(X_train[:1]).reshape(256,256,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lHI60pmr_YOT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = model.get_layer('conv2d_31').output\n",
        "flatten = Flatten()(x)\n",
        "encoder = Model(inputs=model.input, outputs=flatten)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HP6t9omZ_lBa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "try:\n",
        "    model_json = encoder.to_json()\n",
        "    with open(\"/content/drive/My Drive/similiarautoencoder_encoder_final_256new_unet_only_autoencoder_use_slider.json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "except:\n",
        "    pass\n",
        "# serialize weights to HDF5\n",
        "encoder.save_weights(\"/content/drive/My Drive/similiarautoencoder_encoder_final_256new_unet_only_autoencoder_use_slider.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}